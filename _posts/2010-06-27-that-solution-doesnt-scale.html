--- 
layout: post
title: "\xE2\x80\x9CThat solution doesn\xE2\x80\x99t scale\xE2\x80\x9D"
published: true
meta: {}

tags: 
- Architecture
- Azure
- Cloud Computing
type: post
status: publish
---
<p>I posted yesterday about <a href="http://blogs.southworks.net/mwoloski/2010/06/26/poor-mans-memcached-for-windows-azure/">a poor man’s distributed caching solution</a> using Windows Azure queues and ASP.NET cache. I’ve got an interesting comment in twitter: </p>  <p><a href="http://blogs.southworks.net/mwoloski/files/2010/06/image14.png"><img style="float: none;margin-left: auto;margin-right: auto" border="0" alt="image" src="http://blogs.southworks.net/mwoloski/files/2010/06/image-thumb11.png" width="421" height="38" /></a> </p>  <p>My short answer is that there aren’t solutions that scale or doesn’t scale. The scalability is a quality attribute of a system and it varies depending on the context. A <strong><em>good system </em></strong>is the one that is easily adaptable to new contexts and a <strong><em>good solution </em></strong>is the one that is the most convenient in a local context.</p>  <h2>Putting things in context</h2>  <p>So here is the analysis of the solution proposed and the context where it might applies. </p>  <p>I used the following parameters in the calculation:</p>  <ul>   <li><strong>Time to dequeue 32 messages at a time</strong>: 1600 milliseconds (<a href="http://azurescope.cloudapp.net/BenchmarkTestCases/tc/2b3cc07f-aea6-4d27-a3c3-0dad340a0e55/">source</a>) </li>    <li><strong>Time spent notifying ASP.NET cache the dependency changed:</strong> 300 milliseconds (this is a worst case scenario, it is actually in the nanosecs scale) </li> </ul>  <p><a href="http://blogs.southworks.net/mwoloski/files/2010/06/image15.png"><img border="0" alt="image" src="http://blogs.southworks.net/mwoloski/files/2010/06/image-thumb12.png" width="718" height="704" /></a> </p>  <p></p>  <p></p>  <p>Some conclusions you can take from this</p>  <ul>   <li>From 1 to 1000 items updated per second (i.e. items invalidated) there is a penalty of 3 minutes (in the worst case) to invalidate the cache of those 1000 items. We are talking about items invalidated<strong> PER SECOND</strong>. Even having 1 update per second is a lot, in certain systems, so this seems to be good enough for many applications. </li>    <li>Passing the 1000 items barrier, the time to invalidate all the cache items could be unacceptable (e.g.: you don’t want to wait hours to invalidate the cache). However, if you have more than 1000 updates per seconds, you are probably having other problems ;)</li> </ul>  <h2>So what is the drawback compared to a distributed cache?</h2>  <p>If you compare this solution to something like memcached, the main difference resides when you have lots of web servers in a farm. This is because memcached will replicate and keep synchronized the cache items between nodes. So when you insert an item in memcached it is available to all the web servers almost immediately. However, when using the ASP.NET Cache and the cache dependency mechanism, when the item is invalidated, EACH web server will have to retrieve the item again and insert it in the cache. Retrieving the resource is the expensive operation, but not invalidating the cache.</p>  <p>I hope this clarifies a bit what I meant by “<a href="http://blogs.southworks.net/mwoloski/2010/06/26/poor-mans-memcached-for-windows-azure/">poor man’s memcached</a>” :)</p>
